{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92c587b8-c9bd-449f-9806-3661dc5bdaec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37aa65b9-1cad-4b80-a767-0a424dafbd6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dnn(nn.Module):\n",
    "    def __init__(self, hidden_units, dropout=0.):\n",
    "        super(Dnn, self).__init__()\n",
    "        self.dnn_network = nn.ModuleList([nn.Linear(layer[0], layer[1]) for layer in list(zip(hidden_units[:-1], hidden_units[1:]))])\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    def forward(self, x):\n",
    "        for linear in self.dnn_network:\n",
    "            x = linear(x)\n",
    "            x = F.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0f675ae0-9f12-47b4-8b14-1bdc9773f952",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NFM(nn.Module):\n",
    "    def __init__(self, feature_columns, hidden_units, dnn_dropout=0.):\n",
    "        super(NFM, self).__init__()\n",
    "        self.dense_feature_cols, self.sparse_feature_cols = feature_columns\n",
    "        \n",
    "        #embedding\n",
    "        self.embed_layers = nn.ModuleDict({\n",
    "            'embed_'+str(i):nn.Embedding(num_embeddings=feat['feat_num'], embedding_dim=feat['embed_dim']) for i, feat in enumerate(self.sparse_feature_cols)\n",
    "        })\n",
    "        \n",
    "        self.fea_num = len(self.dense_feature_cols) + self.sparse_feature_cols[0]['embed_dim']\n",
    "        hidden_units.insert(0, self.fea_num)\n",
    "        \n",
    "        self.bn = nn.BatchNorm1d(self.fea_num)\n",
    "        self.dnn_network = Dnn(hidden_units, dnn_dropout)\n",
    "        self.nn_final_linear = nn.Linear(hidden_units[-1], 1)\n",
    "    def forward(self, x):\n",
    "        dense_inputs, sparse_inputs = x[:, :len(self.dense_feature_cols)], x[:, len(self.dense_feature_cols):]\n",
    "        sparse_inputs = sparse_inputs.long()\n",
    "        sparse_embeds = [self.embed_layers['embed_'+str(i)](sparse_inputs[:, i]) for i in range(sparse_inputs.shape[1])]\n",
    "        sparse_embeds = torch.stack(sparse_embeds)  #embedding堆起来，(field_dim, None, embed_dim)\n",
    "        sparse_embeds = sparse_embeds.permute((1, 0, 2))\n",
    "        \n",
    "        #这里得到embedding向量之后sparse_embeds(None, field_num, embed_dim)，进行特征交叉层\n",
    "        embed_cross = 1/2 * (torch.pow(torch.sum(sparse_embeds, dim=1),2) - torch.sum(torch.pow(sparse_embeds, 2), dim=1)) #(None, embed_dim)\n",
    "        \n",
    "        #把离散特征和连续特征进行拼接作为FM和DNN的输入\n",
    "        x = torch.cat([embed_cross, dense_inputs], dim=-1)\n",
    "        #BatchNormalization\n",
    "        x = self.bn(x)\n",
    "        #deep\n",
    "        dnn_outputs = self.nn_final_linear(self.dnn_network(x))\n",
    "        outputs = F.sigmoid(dnn_outputs)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "db9dec7a-8643-4bb9-9c2c-6169d34935a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[{'feat': 'I1'}, {'feat': 'I2'}, {'feat': 'I3'}, {'feat': 'I4'}, {'feat': 'I5'}, {'feat': 'I6'}, {'feat': 'I7'}, {'feat': 'I8'}, {'feat': 'I9'}, {'feat': 'I10'}, {'feat': 'I11'}, {'feat': 'I12'}, {'feat': 'I13'}], [{'feat': 'C1', 'feat_num': 79, 'embed_dim': 8}, {'feat': 'C2', 'feat_num': 252, 'embed_dim': 8}, {'feat': 'C3', 'feat_num': 1293, 'embed_dim': 8}, {'feat': 'C4', 'feat_num': 1043, 'embed_dim': 8}, {'feat': 'C5', 'feat_num': 30, 'embed_dim': 8}, {'feat': 'C6', 'feat_num': 7, 'embed_dim': 8}, {'feat': 'C7', 'feat_num': 1164, 'embed_dim': 8}, {'feat': 'C8', 'feat_num': 39, 'embed_dim': 8}, {'feat': 'C9', 'feat_num': 2, 'embed_dim': 8}, {'feat': 'C10', 'feat_num': 908, 'embed_dim': 8}, {'feat': 'C11', 'feat_num': 926, 'embed_dim': 8}, {'feat': 'C12', 'feat_num': 1239, 'embed_dim': 8}, {'feat': 'C13', 'feat_num': 824, 'embed_dim': 8}, {'feat': 'C14', 'feat_num': 20, 'embed_dim': 8}, {'feat': 'C15', 'feat_num': 819, 'embed_dim': 8}, {'feat': 'C16', 'feat_num': 1159, 'embed_dim': 8}, {'feat': 'C17', 'feat_num': 9, 'embed_dim': 8}, {'feat': 'C18', 'feat_num': 534, 'embed_dim': 8}, {'feat': 'C19', 'feat_num': 201, 'embed_dim': 8}, {'feat': 'C20', 'feat_num': 4, 'embed_dim': 8}, {'feat': 'C21', 'feat_num': 1204, 'embed_dim': 8}, {'feat': 'C22', 'feat_num': 7, 'embed_dim': 8}, {'feat': 'C23', 'feat_num': 12, 'embed_dim': 8}, {'feat': 'C24', 'feat_num': 729, 'embed_dim': 8}, {'feat': 'C25', 'feat_num': 33, 'embed_dim': 8}, {'feat': 'C26', 'feat_num': 554, 'embed_dim': 8}]]\n",
      "(1439, 40) (160, 40) (400, 40)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('./data/Criteo_sample.txt')\n",
    "train_set, test_set = train_test_split(data, test_size=0.2, random_state=2024)\n",
    "\n",
    "train_label = train_set['label']\n",
    "del train_set['label']\n",
    "test_label = test_set['label']\n",
    "del test_set['label']\n",
    "data_df = pd.concat((train_set, test_set))\n",
    "\n",
    "\n",
    "sparse_feas = [col for col in data_df.columns if col[0] == 'C']\n",
    "dense_feas = [col for col in data_df.columns if col[0] == 'I']\n",
    "\n",
    "data_df[sparse_feas] = data_df[sparse_feas].fillna('-1')\n",
    "data_df[dense_feas] = data_df[dense_feas].fillna(0)\n",
    "\n",
    "def sparseFeature(feat, feat_num, embed_dim=4):\n",
    "    return {'feat':feat, 'feat_num':feat_num, 'embed_dim':embed_dim}\n",
    "def denseFeature(feat):\n",
    "    return {'feat':feat}\n",
    "embed_dim = 8\n",
    "feature_columns = [[denseFeature(feat) for feat in dense_feas]] + [[sparseFeature(feat, len(data_df[feat].unique()), embed_dim=embed_dim) for feat in sparse_feas]]\n",
    "\n",
    "for feat in sparse_feas:\n",
    "    le = LabelEncoder()\n",
    "    data_df[feat] = le.fit_transform(data_df[feat])\n",
    "\n",
    "mms = MinMaxScaler()\n",
    "data_df[dense_feas] = mms.fit_transform(data_df[dense_feas])\n",
    "\n",
    "train = data_df[:train_set.shape[0]]\n",
    "test = data_df[train_set.shape[0]:]\n",
    "\n",
    "train['label'] = train_label\n",
    "test['label'] = test_label\n",
    "\n",
    "train_set, val_set = train_test_split(train, test_size=0.1, random_state=2020)\n",
    "\n",
    "train_set.reset_index(drop=True, inplace=True)\n",
    "val_set.reset_index(drop=True, inplace=True)\n",
    "test.reset_index(drop=True, inplace=True)\n",
    "print(feature_columns)\n",
    "print(train_set.shape, val_set.shape, test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "66ac71f7-8e25-4955-9e00-c6c36e016c85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NFM(\n",
       "  (embed_layers): ModuleDict(\n",
       "    (embed_0): Embedding(79, 8)\n",
       "    (embed_1): Embedding(252, 8)\n",
       "    (embed_2): Embedding(1293, 8)\n",
       "    (embed_3): Embedding(1043, 8)\n",
       "    (embed_4): Embedding(30, 8)\n",
       "    (embed_5): Embedding(7, 8)\n",
       "    (embed_6): Embedding(1164, 8)\n",
       "    (embed_7): Embedding(39, 8)\n",
       "    (embed_8): Embedding(2, 8)\n",
       "    (embed_9): Embedding(908, 8)\n",
       "    (embed_10): Embedding(926, 8)\n",
       "    (embed_11): Embedding(1239, 8)\n",
       "    (embed_12): Embedding(824, 8)\n",
       "    (embed_13): Embedding(20, 8)\n",
       "    (embed_14): Embedding(819, 8)\n",
       "    (embed_15): Embedding(1159, 8)\n",
       "    (embed_16): Embedding(9, 8)\n",
       "    (embed_17): Embedding(534, 8)\n",
       "    (embed_18): Embedding(201, 8)\n",
       "    (embed_19): Embedding(4, 8)\n",
       "    (embed_20): Embedding(1204, 8)\n",
       "    (embed_21): Embedding(7, 8)\n",
       "    (embed_22): Embedding(12, 8)\n",
       "    (embed_23): Embedding(729, 8)\n",
       "    (embed_24): Embedding(33, 8)\n",
       "    (embed_25): Embedding(554, 8)\n",
       "  )\n",
       "  (bn): BatchNorm1d(21, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (dnn_network): Dnn(\n",
       "    (dnn_network): ModuleList(\n",
       "      (0): Linear(in_features=21, out_features=128, bias=True)\n",
       "      (1): Linear(in_features=128, out_features=64, bias=True)\n",
       "      (2): Linear(in_features=64, out_features=32, bias=True)\n",
       "    )\n",
       "    (dropout): Dropout(p=0.0, inplace=False)\n",
       "  )\n",
       "  (nn_final_linear): Linear(in_features=32, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#建立模型\n",
    "hidden_units = [128, 64, 32]\n",
    "dnn_dropout = 0.\n",
    "model = NFM(feature_columns, hidden_units, dnn_dropout)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0aa79b4a-8701-4420-bbe2-4959f891ba69",
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_x = train_set.drop('label', axis=1).values\n",
    "trn_y = train_set['label'].values\n",
    "val_x = val_set.drop('label', axis=1).values\n",
    "val_y = val_set['label'].values\n",
    "dl_train_dataset = TensorDataset(torch.tensor(trn_x).float(), torch.tensor(trn_y).float())\n",
    "dl_val_dataset = TensorDataset(torch.tensor(val_x).float(), torch.tensor(val_y).float())\n",
    "\n",
    "dl_train = DataLoader(dl_train_dataset, shuffle=True, batch_size=32)\n",
    "dl_val = DataLoader(dl_val_dataset, shuffle=True, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2e2cd6d3-7969-41d1-b836-144389dc61e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start_training.........\n",
      "================================================================\n",
      "[step=10] loss: 0.678, auc: 0.539\n",
      "[step=20] loss: 0.674, auc: 0.489\n",
      "[step=30] loss: 0.670, auc: 0.507\n",
      "[step=40] loss: 0.666, auc: 0.521\n",
      "\n",
      "EPOCH=1, loss=0.663, auc = 0.526, val_loss=0.667, val_auc = 0.442\n",
      "\n",
      "================================================================================\n",
      "[step=10] loss: 0.636, auc: 0.493\n",
      "[step=20] loss: 0.637, auc: 0.510\n",
      "[step=30] loss: 0.627, auc: 0.508\n",
      "[step=40] loss: 0.624, auc: 0.524\n",
      "\n",
      "EPOCH=2, loss=0.619, auc = 0.516, val_loss=0.635, val_auc = 0.465\n",
      "\n",
      "================================================================================\n",
      "[step=10] loss: 0.580, auc: 0.532\n",
      "[step=20] loss: 0.579, auc: 0.523\n",
      "[step=30] loss: 0.574, auc: 0.533\n",
      "[step=40] loss: 0.567, auc: 0.543\n",
      "\n",
      "EPOCH=3, loss=0.563, auc = 0.551, val_loss=0.613, val_auc = 0.495\n",
      "\n",
      "================================================================================\n",
      "[step=10] loss: 0.537, auc: 0.552\n",
      "[step=20] loss: 0.544, auc: 0.540\n",
      "[step=30] loss: 0.523, auc: 0.547\n",
      "[step=40] loss: 0.514, auc: 0.579\n",
      "\n",
      "EPOCH=4, loss=0.512, auc = 0.589, val_loss=0.602, val_auc = 0.491\n",
      "\n",
      "================================================================================\n",
      "[step=10] loss: 0.513, auc: 0.645\n",
      "[step=20] loss: 0.502, auc: 0.604\n",
      "[step=30] loss: 0.489, auc: 0.624\n",
      "[step=40] loss: 0.484, auc: 0.626\n",
      "\n",
      "EPOCH=5, loss=0.485, auc = 0.633, val_loss=0.608, val_auc = 0.536\n",
      "\n",
      "================================================================================\n",
      "[step=10] loss: 0.486, auc: 0.678\n",
      "[step=20] loss: 0.495, auc: 0.658\n",
      "[step=30] loss: 0.479, auc: 0.661\n",
      "[step=40] loss: 0.476, auc: 0.666\n",
      "\n",
      "EPOCH=6, loss=0.474, auc = 0.662, val_loss=0.600, val_auc = 0.576\n",
      "\n",
      "================================================================================\n",
      "[step=10] loss: 0.468, auc: 0.699\n",
      "[step=20] loss: 0.458, auc: 0.698\n",
      "[step=30] loss: 0.451, auc: 0.690\n",
      "[step=40] loss: 0.461, auc: 0.683\n",
      "\n",
      "EPOCH=7, loss=0.470, auc = 0.680, val_loss=0.601, val_auc = 0.583\n",
      "\n",
      "================================================================================\n",
      "[step=10] loss: 0.427, auc: 0.780\n",
      "[step=20] loss: 0.427, auc: 0.773\n",
      "[step=30] loss: 0.448, auc: 0.726\n",
      "[step=40] loss: 0.458, auc: 0.707\n",
      "\n",
      "EPOCH=8, loss=0.465, auc = 0.702, val_loss=0.591, val_auc = 0.567\n",
      "\n",
      "================================================================================\n",
      "[step=10] loss: 0.450, auc: 0.704\n",
      "[step=20] loss: 0.456, auc: 0.705\n",
      "[step=30] loss: 0.479, auc: 0.690\n",
      "[step=40] loss: 0.465, auc: 0.695\n",
      "\n",
      "EPOCH=9, loss=0.463, auc = 0.698, val_loss=0.581, val_auc = 0.627\n",
      "\n",
      "================================================================================\n",
      "[step=10] loss: 0.474, auc: 0.714\n",
      "[step=20] loss: 0.464, auc: 0.708\n",
      "[step=30] loss: 0.482, auc: 0.700\n",
      "[step=40] loss: 0.458, auc: 0.713\n",
      "\n",
      "EPOCH=10, loss=0.457, auc = 0.713, val_loss=0.581, val_auc = 0.618\n",
      "\n",
      "================================================================================\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "def auc(y_pred, y_true):\n",
    "    pred = y_pred.data\n",
    "    y = y_true.data\n",
    "    return roc_auc_score(y, pred)\n",
    "\n",
    "loss_func = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=0.0001)\n",
    "metric_func = auc\n",
    "metric_name = 'auc'\n",
    "epochs = 10\n",
    "log_step_freq = 10\n",
    "\n",
    "dfhistory = pd.DataFrame(columns=['epoch', 'loss', metric_name, 'val_loss', 'val_'+metric_name])\n",
    "\n",
    "print('start_training.........')\n",
    "\n",
    "print('========'*8)\n",
    "\n",
    "for epoch in range(1, epochs+1):\n",
    "    \n",
    "    # 训练阶段\n",
    "    model.train()\n",
    "    loss_sum = 0.0\n",
    "    metric_sum = 0.0\n",
    "    step = 1\n",
    "    \n",
    "\n",
    "    \n",
    "    for step, (features, labels) in enumerate(dl_train, 1):\n",
    "        # 梯度清零\n",
    "        optimizer.zero_grad()\n",
    "        labels = labels.view(-1, 1)\n",
    "        \n",
    "        # 正向传播\n",
    "        predictions = model(features);\n",
    "        loss = loss_func(predictions, labels)\n",
    "        try:\n",
    "            metric = metric_func(predictions, labels)\n",
    "        except ValueError:\n",
    "            pass\n",
    "        \n",
    "        # 反向传播\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # 打印batch级别日志\n",
    "        loss_sum += loss.item()\n",
    "        metric_sum += metric.item()\n",
    "        if step % log_step_freq == 0:\n",
    "            print((\"[step=%d] loss: %.3f, \" + metric_name + \": %.3f\") % (step, loss_sum/step, metric_sum/step));\n",
    "    \n",
    "    # 验证阶段\n",
    "    model.eval()\n",
    "    val_loss_sum = 0.0\n",
    "    val_metric_sum = 0.0\n",
    "    val_step = 1\n",
    "    \n",
    "    for val_step, (features, labels) in enumerate(dl_val, 1):\n",
    "        labels = labels.view(-1, 1)\n",
    "        with torch.no_grad():\n",
    "            predictions = model(features)\n",
    "            val_loss = loss_func(predictions, labels)\n",
    "            try:\n",
    "                val_metric = metric_func(predictions, labels)\n",
    "            except ValueError:\n",
    "                pass\n",
    "        \n",
    "        val_loss_sum += val_loss.item()\n",
    "        val_metric_sum += val_metric.item()\n",
    "    \n",
    "    # 记录日志\n",
    "    info = (epoch, loss_sum/step, metric_sum/step, val_loss_sum/val_step, val_metric_sum/val_step)\n",
    "    dfhistory.loc[epoch-1] = info\n",
    "    \n",
    "    # 打印日志\n",
    "    print((\"\\nEPOCH=%d, loss=%.3f, \" + metric_name + \" = %.3f, val_loss=%.3f, \" + \"val_\" + metric_name + \" = %.3f\") %info)\n",
    "    print('\\n' + '=========='* 8)\n",
    "    \n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cac207c2-6b38-41f1-bfc3-c823de746d6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_auc:0.618 test_acc:0.775\n"
     ]
    }
   ],
   "source": [
    "# 预测\n",
    "from sklearn.metrics import accuracy_score\n",
    "test_x = test.drop('label', axis=1).values\n",
    "test_y = test['label'].values\n",
    "y_pred_probs = model(torch.tensor(test_x).float())\n",
    "y_pred = torch.where(y_pred_probs>0.5, torch.ones_like(y_pred_probs), torch.zeros_like(y_pred_probs))\n",
    "\n",
    "test_auc = roc_auc_score(test_y, y_pred_probs.data.numpy())\n",
    "test_acc = accuracy_score(test_y, y_pred.data.numpy())\n",
    "print('test_auc:%.3f test_acc:%.3f'%(test_auc, test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a793245f-cb6a-4892-b98c-a845a5be6d1b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
