{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e5a8938-0156-4f9f-8622-ea8b38fa9fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader,TensorDataset\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8a8a49fd-ce54-4a4c-a169-e0b28e4cbc1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepCrossing(nn.Module):\n",
    "    def __init__(self, feature_columns, hidden_units, dropout=0., embed_dim=10, output_dim=1):\n",
    "        super(DeepCrossing, self).__init__()\n",
    "        self.dense_feature_cols, self.sparse_feature_cols = feature_columns\n",
    "\n",
    "        self.embed_layers = nn.ModuleDict({\n",
    "            'embed_' + str(i): nn.Embedding(num_embeddings=feat['feat_num'], embedding_dim=feat['embed_dim']) for i, feat in enumerate(self.sparse_feature_cols)\n",
    "        })\n",
    "        \n",
    "        # 统计embedding层的输出维度\n",
    "        embed_dim_sum = sum([feat['embed_dim'] for feat in self.sparse_feature_cols])\n",
    "        \n",
    "        # stack layers的总维度\n",
    "        dim_stack = len(self.dense_feature_cols) + embed_dim_sum\n",
    "        \n",
    "        # 残差层，可能会有多层\n",
    "        self.res_layers = nn.ModuleList([\n",
    "            Residual_block(unit, dim_stack) for unit in hidden_units\n",
    "        ])\n",
    "\n",
    "        # dropout层\n",
    "        self.res_dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        # 线性层\n",
    "        self.linear = nn.Linear(dim_stack, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        dense_inputs, sparse_inputs = x[:, :13], x[:, 13:]\n",
    "        sparse_inputs = sparse_inputs.long()  # 需要转成长张量，这个是embedding的输入格式要求\n",
    "        sparse_embeds = [self.embed_layers['embed_'+str(i)](sparse_inputs[:, i]) for i in range(sparse_inputs.shape[1])]\n",
    "        sparse_embed = torch.cat(sparse_embeds, dim=-1)\n",
    "        \n",
    "        stack = torch.cat([sparse_embed, dense_inputs], dim=-1)\n",
    "        r = stack\n",
    "        for res in self.res_layers:\n",
    "            r = res(r)\n",
    "        r = self.res_dropout(r)\n",
    "        outputs = torch.sigmoid(self.linear(r))\n",
    "        outputs = outputs.squeeze(-1)\n",
    "        return outputs\n",
    "\n",
    "class Residual_block(nn.Module):\n",
    "    def __init__(self, hidden_unit, dim_stack):\n",
    "        super(Residual_block, self).__init__()\n",
    "        self.linear1 = nn.Linear(dim_stack, hidden_unit)\n",
    "        self.linear2 = nn.Linear(hidden_unit, dim_stack)\n",
    "        self.relu = nn.ReLU()\n",
    "    def forward(self, x):\n",
    "        orig_x = x.clone()\n",
    "        x = self.linear1(x)\n",
    "        x = self.linear2(x)\n",
    "        output = self.relu(x + orig_x)\n",
    "        return output"
   ]
  },
  {
"cell_type": "code",
   "execution_count": 11,
   "id": "04bf4981-67f8-48c6-8da4-d37823bc050a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[{'feat': 'I1'}, {'feat': 'I2'}, {'feat': 'I3'}, {'feat': 'I4'}, {'feat': 'I5'}, {'feat': 'I6'}, {'feat': 'I7'}, {'feat': 'I8'}, {'feat': 'I9'}, {'feat': 'I10'}, {'feat': 'I11'}, {'feat': 'I12'}, {'feat': 'I13'}], [{'feat': 'C1', 'feat_num': 79, 'embed_dim': 8}, {'feat': 'C2', 'feat_num': 252, 'embed_dim': 8}, {'feat': 'C3', 'feat_num': 1293, 'embed_dim': 8}, {'feat': 'C4', 'feat_num': 1043, 'embed_dim': 8}, {'feat': 'C5', 'feat_num': 30, 'embed_dim': 8}, {'feat': 'C6', 'feat_num': 7, 'embed_dim': 8}, {'feat': 'C7', 'feat_num': 1164, 'embed_dim': 8}, {'feat': 'C8', 'feat_num': 39, 'embed_dim': 8}, {'feat': 'C9', 'feat_num': 2, 'embed_dim': 8}, {'feat': 'C10', 'feat_num': 908, 'embed_dim': 8}, {'feat': 'C11', 'feat_num': 926, 'embed_dim': 8}, {'feat': 'C12', 'feat_num': 1239, 'embed_dim': 8}, {'feat': 'C13', 'feat_num': 824, 'embed_dim': 8}, {'feat': 'C14', 'feat_num': 20, 'embed_dim': 8}, {'feat': 'C15', 'feat_num': 819, 'embed_dim': 8}, {'feat': 'C16', 'feat_num': 1159, 'embed_dim': 8}, {'feat': 'C17', 'feat_num': 9, 'embed_dim': 8}, {'feat': 'C18', 'feat_num': 534, 'embed_dim': 8}, {'feat': 'C19', 'feat_num': 201, 'embed_dim': 8}, {'feat': 'C20', 'feat_num': 4, 'embed_dim': 8}, {'feat': 'C21', 'feat_num': 1204, 'embed_dim': 8}, {'feat': 'C22', 'feat_num': 7, 'embed_dim': 8}, {'feat': 'C23', 'feat_num': 12, 'embed_dim': 8}, {'feat': 'C24', 'feat_num': 729, 'embed_dim': 8}, {'feat': 'C25', 'feat_num': 33, 'embed_dim': 8}, {'feat': 'C26', 'feat_num': 554, 'embed_dim': 8}]]\n",
      "(1439, 40) (160, 40) (400, 40)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c1567a41-130e-4346-8b23-abd33a822916",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "071b4f1d-754f-4176-8f22-d16c871ac846",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeepCrossing(\n",
       "  (embed_layers): ModuleDict(\n",
       "    (embed_0): Embedding(79, 8)\n",
       "    (embed_1): Embedding(252, 8)\n",
       "    (embed_2): Embedding(1293, 8)\n",
       "    (embed_3): Embedding(1043, 8)\n",
       "    (embed_4): Embedding(30, 8)\n",
       "    (embed_5): Embedding(7, 8)\n",
       "    (embed_6): Embedding(1164, 8)\n",
       "    (embed_7): Embedding(39, 8)\n",
       "    (embed_8): Embedding(2, 8)\n",
       "    (embed_9): Embedding(908, 8)\n",
       "    (embed_10): Embedding(926, 8)\n",
       "    (embed_11): Embedding(1239, 8)\n",
       "    (embed_12): Embedding(824, 8)\n",
       "    (embed_13): Embedding(20, 8)\n",
       "    (embed_14): Embedding(819, 8)\n",
       "    (embed_15): Embedding(1159, 8)\n",
       "    (embed_16): Embedding(9, 8)\n",
       "    (embed_17): Embedding(534, 8)\n",
       "    (embed_18): Embedding(201, 8)\n",
       "    (embed_19): Embedding(4, 8)\n",
       "    (embed_20): Embedding(1204, 8)\n",
       "    (embed_21): Embedding(7, 8)\n",
       "    (embed_22): Embedding(12, 8)\n",
       "    (embed_23): Embedding(729, 8)\n",
       "    (embed_24): Embedding(33, 8)\n",
       "    (embed_25): Embedding(554, 8)\n",
       "  )\n",
       "  (res_layers): ModuleList(\n",
       "    (0): Residual_block(\n",
       "      (linear1): Linear(in_features=221, out_features=256, bias=True)\n",
       "      (linear2): Linear(in_features=256, out_features=221, bias=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (1): Residual_block(\n",
       "      (linear1): Linear(in_features=221, out_features=128, bias=True)\n",
       "      (linear2): Linear(in_features=128, out_features=221, bias=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (2): Residual_block(\n",
       "      (linear1): Linear(in_features=221, out_features=64, bias=True)\n",
       "      (linear2): Linear(in_features=64, out_features=221, bias=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (res_dropout): Dropout(p=0.0, inplace=False)\n",
       "  (linear): Linear(in_features=221, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_units = [256, 128, 64]\n",
    "batch_size = 64\n",
    "num_workers = 4\n",
    "lr = 1e-4\n",
    "epochs = 20\n",
    "\n",
    "model = DeepCrossing(feature_columns, hidden_units)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "169515d2-7253-4250-8cdb-b1edcef638d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeepCrossing(\n",
       "  (embed_layers): ModuleDict(\n",
       "    (embed_0): Embedding(79, 8)\n",
       "    (embed_1): Embedding(252, 8)\n",
       "    (embed_2): Embedding(1293, 8)\n",
       "    (embed_3): Embedding(1043, 8)\n",
       "    (embed_4): Embedding(30, 8)\n",
       "    (embed_5): Embedding(7, 8)\n",
       "    (embed_6): Embedding(1164, 8)\n",
       "    (embed_7): Embedding(39, 8)\n",
       "    (embed_8): Embedding(2, 8)\n",
       "    (embed_9): Embedding(908, 8)\n",
       "    (embed_10): Embedding(926, 8)\n",
       "    (embed_11): Embedding(1239, 8)\n",
       "    (embed_12): Embedding(824, 8)\n",
       "    (embed_13): Embedding(20, 8)\n",
       "    (embed_14): Embedding(819, 8)\n",
       "    (embed_15): Embedding(1159, 8)\n",
       "    (embed_16): Embedding(9, 8)\n",
       "    (embed_17): Embedding(534, 8)\n",
       "    (embed_18): Embedding(201, 8)\n",
       "    (embed_19): Embedding(4, 8)\n",
       "    (embed_20): Embedding(1204, 8)\n",
       "    (embed_21): Embedding(7, 8)\n",
       "    (embed_22): Embedding(12, 8)\n",
       "    (embed_23): Embedding(729, 8)\n",
       "    (embed_24): Embedding(33, 8)\n",
       "    (embed_25): Embedding(554, 8)\n",
       "  )\n",
       "  (res_layers): ModuleList(\n",
       "    (0): Residual_block(\n",
       "      (linear1): Linear(in_features=221, out_features=256, bias=True)\n",
       "      (linear2): Linear(in_features=256, out_features=221, bias=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (1): Residual_block(\n",
       "      (linear1): Linear(in_features=221, out_features=128, bias=True)\n",
       "      (linear2): Linear(in_features=128, out_features=221, bias=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (2): Residual_block(\n",
       "      (linear1): Linear(in_features=221, out_features=64, bias=True)\n",
       "      (linear2): Linear(in_features=64, out_features=221, bias=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (3): Residual_block(\n",
       "      (linear1): Linear(in_features=221, out_features=32, bias=True)\n",
       "      (linear2): Linear(in_features=32, out_features=221, bias=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (res_dropout): Dropout(p=0.0, inplace=False)\n",
       "  (linear): Linear(in_features=221, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_units = [256, 128, 64, 32]\n",
    "model = DeepCrossing(feature_columns, hidden_units)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f6f58209-62ff-4fc1-b496-b39914ffac8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start_training.........\n",
      "================================================================\n",
      "[step=10] loss: 0.601, auc: 0.450\n",
      "[step=20] loss: 0.549, auc: 0.479\n",
      "[step=30] loss: 0.554, auc: 0.474\n",
      "[step=40] loss: 0.539, auc: 0.488\n",
      "\n",
      "EPOCH=1, loss=0.537, auc = 0.497, val_loss=0.475, val_auc = 0.634\n",
      "\n",
      "================================================================================\n",
      "[step=10] loss: 0.463, auc: 0.638\n",
      "[step=20] loss: 0.483, auc: 0.589\n",
      "[step=30] loss: 0.483, auc: 0.608\n",
      "[step=40] loss: 0.490, auc: 0.606\n",
      "\n",
      "EPOCH=2, loss=0.493, auc = 0.611, val_loss=0.465, val_auc = 0.669\n",
      "\n",
      "================================================================================\n",
      "[step=10] loss: 0.474, auc: 0.717\n",
      "[step=20] loss: 0.470, auc: 0.710\n",
      "[step=30] loss: 0.450, auc: 0.713\n",
      "[step=40] loss: 0.469, auc: 0.711\n",
      "\n",
      "EPOCH=3, loss=0.472, auc = 0.709, val_loss=0.458, val_auc = 0.691\n",
      "\n",
      "================================================================================\n",
      "[step=10] loss: 0.448, auc: 0.780\n",
      "[step=20] loss: 0.455, auc: 0.755\n",
      "[step=30] loss: 0.445, auc: 0.761\n",
      "[step=40] loss: 0.453, auc: 0.751\n",
      "\n",
      "EPOCH=4, loss=0.450, auc = 0.753, val_loss=0.451, val_auc = 0.676\n",
      "\n",
      "================================================================================\n",
      "[step=10] loss: 0.388, auc: 0.832\n",
      "[step=20] loss: 0.424, auc: 0.797\n",
      "[step=30] loss: 0.423, auc: 0.813\n",
      "[step=40] loss: 0.420, auc: 0.812\n",
      "\n",
      "EPOCH=5, loss=0.431, auc = 0.802, val_loss=0.450, val_auc = 0.693\n",
      "\n",
      "================================================================================\n",
      "[step=10] loss: 0.447, auc: 0.782\n",
      "[step=20] loss: 0.427, auc: 0.779\n",
      "[step=30] loss: 0.421, auc: 0.799\n",
      "[step=40] loss: 0.416, auc: 0.810\n",
      "\n",
      "EPOCH=6, loss=0.410, auc = 0.821, val_loss=0.456, val_auc = 0.666\n",
      "\n",
      "================================================================================\n",
      "[step=10] loss: 0.376, auc: 0.879\n",
      "[step=20] loss: 0.371, auc: 0.857\n",
      "[step=30] loss: 0.389, auc: 0.849\n",
      "[step=40] loss: 0.391, auc: 0.849\n",
      "\n",
      "EPOCH=7, loss=0.386, auc = 0.848, val_loss=0.475, val_auc = 0.684\n",
      "\n",
      "================================================================================\n",
      "[step=10] loss: 0.350, auc: 0.899\n",
      "[step=20] loss: 0.338, auc: 0.900\n",
      "[step=30] loss: 0.363, auc: 0.875\n",
      "[step=40] loss: 0.369, auc: 0.865\n",
      "\n",
      "EPOCH=8, loss=0.364, auc = 0.864, val_loss=0.481, val_auc = 0.654\n",
      "\n",
      "================================================================================\n",
      "[step=10] loss: 0.322, auc: 0.909\n",
      "[step=20] loss: 0.319, auc: 0.911\n",
      "[step=30] loss: 0.332, auc: 0.901\n",
      "[step=40] loss: 0.334, auc: 0.892\n",
      "\n",
      "EPOCH=9, loss=0.336, auc = 0.892, val_loss=0.498, val_auc = 0.624\n",
      "\n",
      "================================================================================\n",
      "[step=10] loss: 0.300, auc: 0.916\n",
      "[step=20] loss: 0.307, auc: 0.912\n",
      "[step=30] loss: 0.307, auc: 0.912\n",
      "[step=40] loss: 0.314, auc: 0.905\n",
      "\n",
      "EPOCH=10, loss=0.311, auc = 0.907, val_loss=0.525, val_auc = 0.640\n",
      "\n",
      "================================================================================\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "def auc(y_pred, y_true):\n",
    "    pred = y_pred.data\n",
    "    y = y_true.data\n",
    "    return roc_auc_score(y, pred)\n",
    "\n",
    "loss_func = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=0.0001)\n",
    "metric_func = auc\n",
    "metric_name = 'auc'\n",
    "epochs = 10\n",
    "log_step_freq = 10\n",
    "\n",
    "dfhistory = pd.DataFrame(columns=['epoch', 'loss', metric_name, 'val_loss', 'val_'+metric_name])\n",
    "\n",
    "print('start_training.........')\n",
    "\n",
    "print('========'*8)\n",
    "\n",
    "for epoch in range(1, epochs+1):\n",
    "    \n",
    "    # 训练阶段\n",
    "    model.train()\n",
    "    loss_sum = 0.0\n",
    "    metric_sum = 0.0\n",
    "    step = 1\n",
    "    \n",
    "\n",
    "    \n",
    "    for step, (features, labels) in enumerate(dl_train, 1):\n",
    "        # 梯度清零\n",
    "        optimizer.zero_grad()\n",
    "        labels = labels.view(-1)\n",
    "        \n",
    "        # 正向传播\n",
    "        predictions = model(features);\n",
    "        loss = loss_func(predictions, labels)\n",
    "        try:\n",
    "            metric = metric_func(predictions, labels)\n",
    "        except ValueError:\n",
    "            pass\n",
    "        \n",
    "        # 反向传播\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # 打印batch级别日志\n",
    "        loss_sum += loss.item()\n",
    "        metric_sum += metric.item()\n",
    "        if step % log_step_freq == 0:\n",
    "            print((\"[step=%d] loss: %.3f, \" + metric_name + \": %.3f\") % (step, loss_sum/step, metric_sum/step));\n",
    "    \n",
    "    # 验证阶段\n",
    "    model.eval()\n",
    "    val_loss_sum = 0.0\n",
    "    val_metric_sum = 0.0\n",
    "    val_step = 1\n",
    "    \n",
    "    for val_step, (features, labels) in enumerate(dl_val, 1):\n",
    "        labels = labels.view(-1)\n",
    "        with torch.no_grad():\n",
    "            predictions = model(features)\n",
    "            val_loss = loss_func(predictions, labels)\n",
    "            try:\n",
    "                val_metric = metric_func(predictions, labels)\n",
    "            except ValueError:\n",
    "                pass\n",
    "        \n",
    "        val_loss_sum += val_loss.item()\n",
    "        val_metric_sum += val_metric.item()\n",
    "    \n",
    "    # 记录日志\n",
    "    info = (epoch, loss_sum/step, metric_sum/step, val_loss_sum/val_step, val_metric_sum/val_step)\n",
    "    dfhistory.loc[epoch-1] = info\n",
    "    \n",
    "    # 打印日志\n",
    "    print((\"\\nEPOCH=%d, loss=%.3f, \" + metric_name + \" = %.3f, val_loss=%.3f, \" + \"val_\" + metric_name + \" = %.3f\") %info)\n",
    "    print('\\n' + '=========='* 8)\n",
    "    \n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6f5a6d05-66aa-45ba-ae52-4379e9fe59c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_auc:0.568 test_acc:0.730\n"
     ]
    }
   ],
   "source": [
    "# 预测\n",
    "from sklearn.metrics import accuracy_score\n",
    "test_x = test.drop('label', axis=1).values\n",
    "test_y = test['label'].values\n",
    "y_pred_probs = model(torch.tensor(test_x).float())\n",
    "y_pred = torch.where(y_pred_probs>0.5, torch.ones_like(y_pred_probs), torch.zeros_like(y_pred_probs))\n",
    "\n",
    "test_auc = roc_auc_score(test_y, y_pred_probs.data.numpy())\n",
    "test_acc = accuracy_score(test_y, y_pred.data.numpy())\n",
    "print('test_auc:%.3f test_acc:%.3f'%(test_auc, test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c1cd517-b48b-4691-978e-5a5791ab08d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f73af7-f3b4-4dfa-b6ff-96a54031326f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa72cb58-7fe1-44e2-be56-a99de7b1bb32",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
